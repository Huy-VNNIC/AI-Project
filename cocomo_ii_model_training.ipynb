{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80d84c3",
   "metadata": {},
   "source": [
    "# Mô hình Ước lượng Nỗ lực Phát triển Phần mềm Dựa trên COCOMO II\n",
    "\n",
    "Notebook này thực hiện huấn luyện các mô hình học máy để ước lượng nỗ lực phát triển phần mềm (effort) dựa trên các tham số đầu vào của mô hình COCOMO II.\n",
    "\n",
    "## Mục tiêu\n",
    "- Kết hợp dữ liệu từ 3 schema khác nhau (LOC, FP, UCP) đã được tiền xử lý\n",
    "- Huấn luyện các mô hình học máy để dự đoán effort:\n",
    "  1. Linear Regression (baseline)\n",
    "  2. Decision Tree Regressor\n",
    "  3. Random Forest Regressor\n",
    "- Đánh giá hiệu suất của các mô hình\n",
    "- Xuất mô hình dưới dạng file .pkl để sử dụng trong tương lai\n",
    "\n",
    "## Các bước thực hiện\n",
    "1. Import thư viện và đọc dữ liệu\n",
    "2. Kết hợp dữ liệu từ các schema khác nhau\n",
    "3. Tiền xử lý dữ liệu cho quá trình huấn luyện\n",
    "4. Huấn luyện và đánh giá các mô hình\n",
    "5. Trực quan hóa kết quả\n",
    "6. Lưu trữ mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab059f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cấu hình hiển thị\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Thiết lập các đường dẫn\n",
    "INPUT_DIR = '/home/huy/Huy-workspace/AI-Project/processed_data'\n",
    "OUTPUT_DIR = '/home/huy/Huy-workspace/AI-Project/models'\n",
    "\n",
    "# Tạo thư mục đầu ra cho mô hình nếu chưa tồn tại\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    print(f\"Đã tạo thư mục {OUTPUT_DIR} để lưu trữ mô hình\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627f48a",
   "metadata": {},
   "source": [
    "## 1. Đọc và Khám phá dữ liệu\n",
    "\n",
    "Đầu tiên, chúng ta sẽ đọc dữ liệu từ các file CSV đã được tiền xử lý theo 3 schema (LOC, FP, UCP) và thực hiện khám phá dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đọc dữ liệu từ các file CSV\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Đọc dữ liệu từ các file CSV đã tiền xử lý theo 3 schema\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary chứa các DataFrame\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    # Đọc metadata để nắm rõ cấu trúc của dữ liệu\n",
    "    metadata_path = os.path.join(INPUT_DIR, 'metadata.json')\n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"Đã tải metadata từ {metadata_path}\")\n",
    "    else:\n",
    "        metadata = {}\n",
    "        print(\"Không tìm thấy file metadata.json\")\n",
    "    \n",
    "    # Đọc dữ liệu LOC\n",
    "    loc_path = os.path.join(INPUT_DIR, 'loc_based.csv')\n",
    "    if os.path.exists(loc_path):\n",
    "        data['loc'] = pd.read_csv(loc_path)\n",
    "        print(f\"Đã tải dữ liệu LOC: {data['loc'].shape[0]} dòng × {data['loc'].shape[1]} cột\")\n",
    "    else:\n",
    "        print(f\"Không tìm thấy file {loc_path}\")\n",
    "        data['loc'] = pd.DataFrame()\n",
    "    \n",
    "    # Đọc dữ liệu FP\n",
    "    fp_path = os.path.join(INPUT_DIR, 'fp_based.csv')\n",
    "    if os.path.exists(fp_path):\n",
    "        data['fp'] = pd.read_csv(fp_path)\n",
    "        print(f\"Đã tải dữ liệu FP: {data['fp'].shape[0]} dòng × {data['fp'].shape[1]} cột\")\n",
    "    else:\n",
    "        print(f\"Không tìm thấy file {fp_path}\")\n",
    "        data['fp'] = pd.DataFrame()\n",
    "    \n",
    "    # Đọc dữ liệu UCP\n",
    "    ucp_path = os.path.join(INPUT_DIR, 'ucp_based.csv')\n",
    "    if os.path.exists(ucp_path):\n",
    "        data['ucp'] = pd.read_csv(ucp_path)\n",
    "        print(f\"Đã tải dữ liệu UCP: {data['ucp'].shape[0]} dòng × {data['ucp'].shape[1]} cột\")\n",
    "    else:\n",
    "        print(f\"Không tìm thấy file {ucp_path}\")\n",
    "        data['ucp'] = pd.DataFrame()\n",
    "    \n",
    "    return data, metadata\n",
    "\n",
    "# Tải dữ liệu\n",
    "data, metadata = load_data()\n",
    "\n",
    "# Hiển thị thông tin về mỗi schema\n",
    "for schema, df in data.items():\n",
    "    if not df.empty:\n",
    "        print(f\"\\n--- Schema {schema.upper()} ---\")\n",
    "        print(f\"Kích thước: {df.shape}\")\n",
    "        print(\"Các cột:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"  - {col} ({df[col].dtype})\")\n",
    "        \n",
    "        print(\"\\nThống kê mô tả:\")\n",
    "        print(df.describe().round(2))\n",
    "        \n",
    "        print(\"\\nMẫu dữ liệu:\")\n",
    "        print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d29594",
   "metadata": {},
   "source": [
    "## 2. Kết hợp dữ liệu từ các schema\n",
    "\n",
    "Chúng ta sẽ kết hợp dữ liệu từ các schema khác nhau thành một tập dữ liệu duy nhất để huấn luyện mô hình. Trước khi kết hợp, chúng ta cần thêm một cột \"schema\" để xác định nguồn của mỗi dòng dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c55bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chuẩn bị và kết hợp dữ liệu\n",
    "def prepare_combined_data(data):\n",
    "    \"\"\"\n",
    "    Chuẩn bị và kết hợp dữ liệu từ các schema khác nhau\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary chứa các DataFrame của từng schema\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame đã kết hợp\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    \n",
    "    # Chuẩn bị dữ liệu LOC\n",
    "    if 'loc' in data and not data['loc'].empty:\n",
    "        loc_df = data['loc'].copy()\n",
    "        loc_df['schema'] = 'LOC'\n",
    "        loc_df['size'] = loc_df['kloc']  # Đổi tên để thống nhất\n",
    "        # Thêm các cột giả để cấu trúc thống nhất với các schema khác\n",
    "        if 'fp' not in loc_df.columns:\n",
    "            loc_df['fp'] = np.nan\n",
    "        if 'ucp' not in loc_df.columns:\n",
    "            loc_df['ucp'] = np.nan\n",
    "        dfs.append(loc_df)\n",
    "    \n",
    "    # Chuẩn bị dữ liệu FP\n",
    "    if 'fp' in data and not data['fp'].empty:\n",
    "        fp_df = data['fp'].copy()\n",
    "        fp_df['schema'] = 'FP'\n",
    "        fp_df['size'] = fp_df['fp']  # Đổi tên để thống nhất\n",
    "        # Thêm các cột giả để cấu trúc thống nhất với các schema khác\n",
    "        if 'kloc' not in fp_df.columns:\n",
    "            fp_df['kloc'] = np.nan\n",
    "        if 'ucp' not in fp_df.columns:\n",
    "            fp_df['ucp'] = np.nan\n",
    "        dfs.append(fp_df)\n",
    "    \n",
    "    # Chuẩn bị dữ liệu UCP\n",
    "    if 'ucp' in data and not data['ucp'].empty:\n",
    "        ucp_df = data['ucp'].copy()\n",
    "        ucp_df['schema'] = 'UCP'\n",
    "        ucp_df['size'] = ucp_df['ucp']  # Đổi tên để thống nhất\n",
    "        # Thêm các cột giả để cấu trúc thống nhất với các schema khác\n",
    "        if 'kloc' not in ucp_df.columns:\n",
    "            ucp_df['kloc'] = np.nan\n",
    "        if 'fp' not in ucp_df.columns:\n",
    "            ucp_df['fp'] = np.nan\n",
    "        dfs.append(ucp_df)\n",
    "    \n",
    "    # Kết hợp các DataFrame\n",
    "    if dfs:\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        # Đảm bảo các cột cần thiết tồn tại\n",
    "        required_columns = ['source', 'schema', 'size', 'effort_pm', 'time_months', 'developers']\n",
    "        for col in required_columns:\n",
    "            if col not in combined_df.columns:\n",
    "                print(f\"Cột {col} không tồn tại trong dữ liệu kết hợp!\")\n",
    "        \n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"Không có dữ liệu nào để kết hợp!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Kết hợp dữ liệu\n",
    "combined_df = prepare_combined_data(data)\n",
    "\n",
    "# Hiển thị thông tin về dữ liệu kết hợp\n",
    "if not combined_df.empty:\n",
    "    print(f\"Dữ liệu kết hợp: {combined_df.shape[0]} dòng × {combined_df.shape[1]} cột\")\n",
    "    print(\"\\nPhân bố theo schema:\")\n",
    "    print(combined_df['schema'].value_counts())\n",
    "    \n",
    "    print(\"\\nThống kê mô tả:\")\n",
    "    print(combined_df[['size', 'effort_pm', 'time_months', 'developers']].describe().round(2))\n",
    "    \n",
    "    print(\"\\nMẫu dữ liệu:\")\n",
    "    print(combined_df.head())\n",
    "else:\n",
    "    print(\"Không thể kết hợp dữ liệu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56952f",
   "metadata": {},
   "source": [
    "## 3. Tiền xử lý dữ liệu cho huấn luyện mô hình\n",
    "\n",
    "Trước khi huấn luyện mô hình, chúng ta cần thực hiện một số bước tiền xử lý:\n",
    "1. Xử lý các giá trị thiếu\n",
    "2. Mã hóa các biến phân loại\n",
    "3. Chuẩn hóa các biến số\n",
    "4. Biến đổi logarithmic (nếu cần)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân tích tương quan giữa các biến\n",
    "if not combined_df.empty:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    numeric_cols = ['size', 'effort_pm', 'time_months', 'developers']\n",
    "    correlation = combined_df[numeric_cols].corr()\n",
    "    mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "    sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', mask=mask, cbar_kws={'shrink': .8})\n",
    "    plt.title('Correlation Matrix for Combined Data')\n",
    "    plt.show()\n",
    "    \n",
    "    # Biểu đồ phân tán theo schema\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    for schema in combined_df['schema'].unique():\n",
    "        subset = combined_df[combined_df['schema'] == schema]\n",
    "        plt.scatter(subset['size'], subset['effort_pm'], label=schema, alpha=0.7)\n",
    "    plt.xlabel('Size')\n",
    "    plt.ylabel('Effort (person-months)')\n",
    "    plt.title('Size vs Effort by Schema')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    for schema in combined_df['schema'].unique():\n",
    "        subset = combined_df[combined_df['schema'] == schema]\n",
    "        plt.scatter(subset['size'], subset['time_months'], label=schema, alpha=0.7)\n",
    "    plt.xlabel('Size')\n",
    "    plt.ylabel('Time (months)')\n",
    "    plt.title('Size vs Time by Schema')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    for schema in combined_df['schema'].unique():\n",
    "        subset = combined_df[combined_df['schema'] == schema]\n",
    "        plt.scatter(subset['size'], subset['developers'], label=schema, alpha=0.7)\n",
    "    plt.xlabel('Size')\n",
    "    plt.ylabel('Developers')\n",
    "    plt.title('Size vs Developers by Schema')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Kiểm tra phân phối của biến mục tiêu (effort_pm)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(combined_df['effort_pm'], kde=True, bins=30)\n",
    "    plt.title('Distribution of Effort (person-months)')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(np.log1p(combined_df['effort_pm']), kde=True, bins=30)\n",
    "    plt.title('Distribution of log(Effort) (person-months)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6625cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiền xử lý dữ liệu cho huấn luyện mô hình\n",
    "def preprocess_data(df, target='effort_pm', log_transform=True):\n",
    "    \"\"\"\n",
    "    Tiền xử lý dữ liệu cho huấn luyện mô hình\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame đầu vào\n",
    "        target: Tên biến mục tiêu\n",
    "        log_transform: Có áp dụng biến đổi logarithmic hay không\n",
    "        \n",
    "    Returns:\n",
    "        X, y, preprocessor: Dữ liệu đã xử lý và bộ tiền xử lý\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"DataFrame đầu vào rỗng!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Tạo bản sao để không ảnh hưởng đến dữ liệu gốc\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Xác định các biến phân loại và số\n",
    "    categorical_cols = ['schema']\n",
    "    numeric_cols = ['size', 'time_months', 'developers']\n",
    "    \n",
    "    # Thêm các cột phân loại khác nếu có\n",
    "    for col in ['sector', 'language', 'methodology', 'applicationtype']:\n",
    "        if col in df.columns:\n",
    "            categorical_cols.append(col)\n",
    "    \n",
    "    # Nếu có cả 3 kích thước, thêm vào làm đặc trưng\n",
    "    if 'kloc' in df.columns and 'kloc' not in numeric_cols:\n",
    "        numeric_cols.append('kloc')\n",
    "    if 'fp' in df.columns and 'fp' not in numeric_cols:\n",
    "        numeric_cols.append('fp')\n",
    "    if 'ucp' in df.columns and 'ucp' not in numeric_cols:\n",
    "        numeric_cols.append('ucp')\n",
    "    \n",
    "    # Sắp xếp lại các đặc trưng để chỉ giữ lại các cột quan trọng\n",
    "    features = categorical_cols + numeric_cols\n",
    "    \n",
    "    # Lọc các cột tồn tại trong dữ liệu\n",
    "    features = [col for col in features if col in df.columns]\n",
    "    \n",
    "    # Chuẩn bị dữ liệu\n",
    "    X = df_copy[features]\n",
    "    y = df_copy[target]\n",
    "    \n",
    "    # Áp dụng biến đổi logarithmic nếu cần\n",
    "    if log_transform:\n",
    "        y = np.log1p(y)\n",
    "    \n",
    "    # Thiết lập bộ tiền xử lý\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, [col for col in numeric_cols if col in X.columns]),\n",
    "            ('cat', categorical_transformer, [col for col in categorical_cols if col in X.columns])\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "    \n",
    "    return X, y, preprocessor\n",
    "\n",
    "# Tiền xử lý dữ liệu\n",
    "X, y, preprocessor = preprocess_data(combined_df, target='effort_pm', log_transform=True)\n",
    "\n",
    "# Phân chia tập huấn luyện và tập kiểm thử\n",
    "if X is not None and y is not None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Tập huấn luyện: {X_train.shape[0]} mẫu\")\n",
    "    print(f\"Tập kiểm thử: {X_test.shape[0]} mẫu\")\n",
    "    \n",
    "    # Hiển thị các đặc trưng được sử dụng\n",
    "    print(\"\\nCác đặc trưng được sử dụng:\")\n",
    "    for col in X.columns:\n",
    "        print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580ea38",
   "metadata": {},
   "source": [
    "## 4. Huấn luyện và đánh giá các mô hình\n",
    "\n",
    "Chúng ta sẽ huấn luyện và đánh giá 3 mô hình:\n",
    "1. Linear Regression (baseline)\n",
    "2. Decision Tree Regressor\n",
    "3. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a555310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đánh giá mô hình\n",
    "def evaluate_model(model, X_test, y_test, model_name, log_transform=True):\n",
    "    \"\"\"\n",
    "    Đánh giá hiệu suất của mô hình\n",
    "    \n",
    "    Args:\n",
    "        model: Mô hình đã huấn luyện\n",
    "        X_test: Dữ liệu kiểm thử\n",
    "        y_test: Nhãn kiểm thử\n",
    "        model_name: Tên mô hình\n",
    "        log_transform: Biến đổi logarithmic đã được áp dụng hay chưa\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary chứa các chỉ số hiệu suất\n",
    "    \"\"\"\n",
    "    # Dự đoán trên tập kiểm thử\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Chuyển đổi ngược lại nếu đã áp dụng biến đổi logarithmic\n",
    "    if log_transform:\n",
    "        y_test_orig = np.expm1(y_test)\n",
    "        y_pred_orig = np.expm1(y_pred)\n",
    "    else:\n",
    "        y_test_orig = y_test\n",
    "        y_pred_orig = y_pred\n",
    "    \n",
    "    # Tính các chỉ số hiệu suất\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Tính các chỉ số hiệu suất trên thang đo gốc\n",
    "    mse_orig = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "    rmse_orig = np.sqrt(mse_orig)\n",
    "    mae_orig = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "    r2_orig = r2_score(y_test_orig, y_pred_orig)\n",
    "    \n",
    "    # Tính MMRE (Mean Magnitude of Relative Error) và Pred(0.25)\n",
    "    are = np.abs(y_pred_orig - y_test_orig) / y_test_orig\n",
    "    mre = np.mean(are)\n",
    "    pred_25 = np.mean(are <= 0.25)  # Tỷ lệ dự đoán trong khoảng 25%\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"\\n--- Kết quả đánh giá mô hình {model_name} ---\")\n",
    "    print(f\"Log-transformed metrics:\")\n",
    "    print(f\"  - MSE: {mse:.4f}\")\n",
    "    print(f\"  - RMSE: {rmse:.4f}\")\n",
    "    print(f\"  - MAE: {mae:.4f}\")\n",
    "    print(f\"  - R^2: {r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nOriginal scale metrics:\")\n",
    "    print(f\"  - MSE: {mse_orig:.4f}\")\n",
    "    print(f\"  - RMSE: {rmse_orig:.4f}\")\n",
    "    print(f\"  - MAE: {mae_orig:.4f}\")\n",
    "    print(f\"  - R^2: {r2_orig:.4f}\")\n",
    "    \n",
    "    print(f\"\\nSoftware engineering specific metrics:\")\n",
    "    print(f\"  - MMRE: {mre:.4f} (Mean Magnitude of Relative Error)\")\n",
    "    print(f\"  - Pred(0.25): {pred_25:.4f} (Percentage of predictions within 25% of actual)\")\n",
    "    \n",
    "    # Trả về các chỉ số hiệu suất\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'mse_orig': mse_orig,\n",
    "        'rmse_orig': rmse_orig,\n",
    "        'mae_orig': mae_orig,\n",
    "        'r2_orig': r2_orig,\n",
    "        'mmre': mre,\n",
    "        'pred_25': pred_25\n",
    "    }\n",
    "\n",
    "# Hàm huấn luyện và đánh giá các mô hình\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, preprocessor, log_transform=True):\n",
    "    \"\"\"\n",
    "    Huấn luyện và đánh giá các mô hình\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test, y_train, y_test: Dữ liệu huấn luyện và kiểm thử\n",
    "        preprocessor: Bộ tiền xử lý dữ liệu\n",
    "        log_transform: Biến đổi logarithmic đã được áp dụng hay chưa\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary chứa các mô hình và kết quả đánh giá\n",
    "    \"\"\"\n",
    "    # Khởi tạo danh sách mô hình\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "    }\n",
    "    \n",
    "    # Tạo pipeline để kết hợp tiền xử lý và mô hình\n",
    "    pipelines = {}\n",
    "    trained_models = {}\n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nĐang huấn luyện mô hình {name}...\")\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Huấn luyện mô hình\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Đánh giá mô hình\n",
    "        result = evaluate_model(pipeline, X_test, y_test, name, log_transform)\n",
    "        results.append(result)\n",
    "        \n",
    "        # Lưu pipeline đã huấn luyện\n",
    "        pipelines[name] = pipeline\n",
    "        trained_models[name] = model\n",
    "    \n",
    "    return {\n",
    "        'pipelines': pipelines,\n",
    "        'models': trained_models,\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "# Huấn luyện và đánh giá các mô hình\n",
    "if X is not None and y is not None:\n",
    "    model_results = train_and_evaluate_models(X_train, X_test, y_train, y_test, preprocessor, log_transform=True)\n",
    "    \n",
    "    # So sánh các mô hình\n",
    "    results_df = pd.DataFrame(model_results['results'])\n",
    "    print(\"\\nSo sánh hiệu suất các mô hình:\")\n",
    "    print(results_df[['model_name', 'r2_orig', 'mmre', 'pred_25']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa kết quả dự đoán\n",
    "def visualize_predictions(models, X_test, y_test, log_transform=True):\n",
    "    \"\"\"\n",
    "    Trực quan hóa kết quả dự đoán của các mô hình\n",
    "    \n",
    "    Args:\n",
    "        models: Dictionary chứa các pipeline đã huấn luyện\n",
    "        X_test: Dữ liệu kiểm thử\n",
    "        y_test: Nhãn kiểm thử\n",
    "        log_transform: Biến đổi logarithmic đã được áp dụng hay chưa\n",
    "    \"\"\"\n",
    "    # Chuyển đổi ngược lại nếu đã áp dụng biến đổi logarithmic\n",
    "    if log_transform:\n",
    "        y_test_orig = np.expm1(y_test)\n",
    "    else:\n",
    "        y_test_orig = y_test\n",
    "    \n",
    "    # Tính toán dự đoán cho từng mô hình\n",
    "    predictions = {}\n",
    "    for name, pipeline in models.items():\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        if log_transform:\n",
    "            predictions[name] = np.expm1(y_pred)\n",
    "        else:\n",
    "            predictions[name] = y_pred\n",
    "    \n",
    "    # Trực quan hóa giá trị thực tế vs dự đoán\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for i, (name, y_pred) in enumerate(predictions.items()):\n",
    "        ax = axes[i]\n",
    "        ax.scatter(y_test_orig, y_pred, alpha=0.5)\n",
    "        \n",
    "        # Vẽ đường y=x (dự đoán hoàn hảo)\n",
    "        max_value = max(np.max(y_test_orig), np.max(y_pred))\n",
    "        min_value = min(np.min(y_test_orig), np.min(y_pred))\n",
    "        ax.plot([min_value, max_value], [min_value, max_value], 'r--')\n",
    "        \n",
    "        ax.set_xlabel('Giá trị thực tế')\n",
    "        ax.set_ylabel('Giá trị dự đoán')\n",
    "        ax.set_title(f'Actual vs Predicted - {name}')\n",
    "        \n",
    "        # Thêm chỉ số R^2\n",
    "        r2 = r2_score(y_test_orig, y_pred)\n",
    "        ax.annotate(f'R² = {r2:.4f}', xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Trực quan hóa phân phối lỗi (residuals)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for i, (name, y_pred) in enumerate(predictions.items()):\n",
    "        ax = axes[i]\n",
    "        residuals = y_pred - y_test_orig\n",
    "        ax.scatter(y_pred, residuals, alpha=0.5)\n",
    "        ax.axhline(y=0, color='r', linestyle='--')\n",
    "        ax.set_xlabel('Giá trị dự đoán')\n",
    "        ax.set_ylabel('Residual')\n",
    "        ax.set_title(f'Residual Plot - {name}')\n",
    "        \n",
    "        # Thêm MMRE\n",
    "        mmre = np.mean(np.abs(residuals) / y_test_orig)\n",
    "        ax.annotate(f'MMRE = {mmre:.4f}', xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Trực quan hóa kết quả dự đoán\n",
    "if X is not None and y is not None and 'pipelines' in model_results:\n",
    "    visualize_predictions(model_results['pipelines'], X_test, y_test, log_transform=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efecb07",
   "metadata": {},
   "source": [
    "## 5. Tinh chỉnh siêu tham số mô hình (Hyperparameter Tuning)\n",
    "\n",
    "Để cải thiện hiệu suất của mô hình, chúng ta sẽ thực hiện tinh chỉnh siêu tham số cho mô hình Decision Tree và Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tinh chỉnh siêu tham số cho mô hình Decision Tree\n",
    "def tune_decision_tree(X_train, y_train, X_test, y_test, preprocessor, log_transform=True):\n",
    "    \"\"\"\n",
    "    Tinh chỉnh siêu tham số cho mô hình Decision Tree Regressor\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test, y_train, y_test: Dữ liệu huấn luyện và kiểm thử\n",
    "        preprocessor: Bộ tiền xử lý dữ liệu\n",
    "        log_transform: Biến đổi logarithmic đã được áp dụng hay chưa\n",
    "        \n",
    "    Returns:\n",
    "        Pipeline đã được tinh chỉnh\n",
    "    \"\"\"\n",
    "    # Khởi tạo pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', DecisionTreeRegressor(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Xác định không gian tìm kiếm siêu tham số\n",
    "    param_grid = {\n",
    "        'model__max_depth': [None, 5, 10, 15, 20],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4, 8]\n",
    "    }\n",
    "    \n",
    "    # Thực hiện tìm kiếm lưới (Grid Search)\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"Đang tinh chỉnh siêu tham số cho Decision Tree...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # In kết quả tốt nhất\n",
    "    print(f\"Siêu tham số tốt nhất: {grid_search.best_params_}\")\n",
    "    print(f\"MSE tốt nhất: {-grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Đánh giá mô hình tốt nhất\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "    result = evaluate_model(best_pipeline, X_test, y_test, \"Decision Tree (Tuned)\", log_transform)\n",
    "    \n",
    "    return best_pipeline, result\n",
    "\n",
    "# Tinh chỉnh siêu tham số cho mô hình Random Forest\n",
    "def tune_random_forest(X_train, y_train, X_test, y_test, preprocessor, log_transform=True):\n",
    "    \"\"\"\n",
    "    Tinh chỉnh siêu tham số cho mô hình Random Forest Regressor\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test, y_train, y_test: Dữ liệu huấn luyện và kiểm thử\n",
    "        preprocessor: Bộ tiền xử lý dữ liệu\n",
    "        log_transform: Biến đổi logarithmic đã được áp dụng hay chưa\n",
    "        \n",
    "    Returns:\n",
    "        Pipeline đã được tinh chỉnh\n",
    "    \"\"\"\n",
    "    # Khởi tạo pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Xác định không gian tìm kiếm siêu tham số\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__max_depth': [None, 10, 20],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    # Thực hiện tìm kiếm lưới (Grid Search)\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"Đang tinh chỉnh siêu tham số cho Random Forest...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # In kết quả tốt nhất\n",
    "    print(f\"Siêu tham số tốt nhất: {grid_search.best_params_}\")\n",
    "    print(f\"MSE tốt nhất: {-grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Đánh giá mô hình tốt nhất\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "    result = evaluate_model(best_pipeline, X_test, y_test, \"Random Forest (Tuned)\", log_transform)\n",
    "    \n",
    "    return best_pipeline, result\n",
    "\n",
    "# Thực hiện tinh chỉnh siêu tham số\n",
    "if X is not None and y is not None:\n",
    "    # Decision Tree\n",
    "    dt_tuned_pipeline, dt_tuned_result = tune_decision_tree(X_train, y_train, X_test, y_test, preprocessor, log_transform=True)\n",
    "    \n",
    "    # Random Forest\n",
    "    rf_tuned_pipeline, rf_tuned_result = tune_random_forest(X_train, y_train, X_test, y_test, preprocessor, log_transform=True)\n",
    "    \n",
    "    # Thêm kết quả của các mô hình đã tinh chỉnh\n",
    "    model_results['results'].append(dt_tuned_result)\n",
    "    model_results['results'].append(rf_tuned_result)\n",
    "    model_results['pipelines']['Decision Tree (Tuned)'] = dt_tuned_pipeline\n",
    "    model_results['pipelines']['Random Forest (Tuned)'] = rf_tuned_pipeline\n",
    "    \n",
    "    # So sánh tất cả các mô hình\n",
    "    results_df = pd.DataFrame(model_results['results'])\n",
    "    print(\"\\nSo sánh hiệu suất tất cả các mô hình:\")\n",
    "    print(results_df[['model_name', 'r2_orig', 'mmre', 'pred_25']].sort_values(by='r2_orig', ascending=False))\n",
    "    \n",
    "    # Trực quan hóa kết quả dự đoán của các mô hình đã tinh chỉnh\n",
    "    tuned_models = {\n",
    "        'Decision Tree (Tuned)': dt_tuned_pipeline,\n",
    "        'Random Forest (Tuned)': rf_tuned_pipeline,\n",
    "        'Linear Regression': model_results['pipelines']['Linear Regression']\n",
    "    }\n",
    "    visualize_predictions(tuned_models, X_test, y_test, log_transform=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17852d",
   "metadata": {},
   "source": [
    "## 6. Thiết kế mô hình COCOMO II mở rộng\n",
    "\n",
    "Tạo một mô hình ước lượng COCOMO II mở rộng bằng cách kết hợp các biến đầu vào khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef138b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình dự đoán đầy đủ dựa trên COCOMO II\n",
    "class CocomoIIPredictor:\n",
    "    \"\"\"\n",
    "    Mô hình COCOMO II mở rộng kết hợp dự đoán dựa trên LOC, FP, và UCP\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path=None):\n",
    "        self.models = {}\n",
    "        self.preprocessor = None\n",
    "        self.log_transform = True\n",
    "        \n",
    "        if model_path:\n",
    "            self.load(model_path)\n",
    "    \n",
    "    def fit(self, models, preprocessor, log_transform=True):\n",
    "        \"\"\"\n",
    "        Lưu các mô hình đã huấn luyện\n",
    "        \n",
    "        Args:\n",
    "            models: Dictionary chứa các pipeline đã huấn luyện\n",
    "            preprocessor: Bộ tiền xử lý dữ liệu\n",
    "            log_transform: Áp dụng biến đổi logarithmic hay không\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.preprocessor = preprocessor\n",
    "        self.log_transform = log_transform\n",
    "        return self\n",
    "    \n",
    "    def predict_effort(self, input_data, model_name='Random Forest (Tuned)'):\n",
    "        \"\"\"\n",
    "        Dự đoán effort dựa trên đầu vào\n",
    "        \n",
    "        Args:\n",
    "            input_data: DataFrame chứa dữ liệu đầu vào\n",
    "            model_name: Tên mô hình để sử dụng\n",
    "            \n",
    "        Returns:\n",
    "            Giá trị effort dự đoán (người-tháng)\n",
    "        \"\"\"\n",
    "        if model_name not in self.models:\n",
    "            raise ValueError(f\"Mô hình '{model_name}' không tồn tại!\")\n",
    "        \n",
    "        model = self.models[model_name]\n",
    "        \n",
    "        # Dự đoán\n",
    "        effort_pred = model.predict(input_data)\n",
    "        \n",
    "        # Chuyển đổi ngược nếu đã áp dụng biến đổi logarithmic\n",
    "        if self.log_transform:\n",
    "            effort_pred = np.expm1(effort_pred)\n",
    "        \n",
    "        return effort_pred\n",
    "    \n",
    "    def predict_schedule(self, effort):\n",
    "        \"\"\"\n",
    "        Dự đoán lịch trình (thời gian) dựa trên effort\n",
    "        Sử dụng công thức COCOMO II: TDEV = 3.67 × (PM)^0.28\n",
    "        \n",
    "        Args:\n",
    "            effort: Effort dự đoán (người-tháng)\n",
    "            \n",
    "        Returns:\n",
    "            Thời gian dự kiến (tháng)\n",
    "        \"\"\"\n",
    "        return 3.67 * (effort ** 0.28)\n",
    "    \n",
    "    def predict_team_size(self, effort, time):\n",
    "        \"\"\"\n",
    "        Dự đoán kích thước đội ngũ dựa trên effort và thời gian\n",
    "        \n",
    "        Args:\n",
    "            effort: Effort dự đoán (người-tháng)\n",
    "            time: Thời gian dự kiến (tháng)\n",
    "            \n",
    "        Returns:\n",
    "            Số lượng nhà phát triển\n",
    "        \"\"\"\n",
    "        return np.ceil(effort / time)\n",
    "    \n",
    "    def predict_all(self, input_data, model_name='Random Forest (Tuned)'):\n",
    "        \"\"\"\n",
    "        Dự đoán effort, thời gian và kích thước đội ngũ\n",
    "        \n",
    "        Args:\n",
    "            input_data: DataFrame chứa dữ liệu đầu vào\n",
    "            model_name: Tên mô hình để sử dụng\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary chứa các kết quả dự đoán\n",
    "        \"\"\"\n",
    "        # Dự đoán effort\n",
    "        effort = self.predict_effort(input_data, model_name)\n",
    "        \n",
    "        # Dự đoán lịch trình\n",
    "        schedule = self.predict_schedule(effort)\n",
    "        \n",
    "        # Dự đoán kích thước đội ngũ\n",
    "        team_size = self.predict_team_size(effort, schedule)\n",
    "        \n",
    "        return {\n",
    "            'effort_pm': effort,\n",
    "            'time_months': schedule,\n",
    "            'developers': team_size\n",
    "        }\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        \"\"\"\n",
    "        Lưu mô hình vào file\n",
    "        \n",
    "        Args:\n",
    "            model_path: Đường dẫn thư mục để lưu mô hình\n",
    "        \"\"\"\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "        \n",
    "        # Lưu các pipeline\n",
    "        for name, pipeline in self.models.items():\n",
    "            file_path = os.path.join(model_path, f\"{name.replace(' ', '_')}.pkl\")\n",
    "            joblib.dump(pipeline, file_path)\n",
    "            print(f\"Đã lưu mô hình {name} vào {file_path}\")\n",
    "        \n",
    "        # Lưu preprocessor\n",
    "        preprocessor_path = os.path.join(model_path, \"preprocessor.pkl\")\n",
    "        joblib.dump(self.preprocessor, preprocessor_path)\n",
    "        print(f\"Đã lưu bộ tiền xử lý vào {preprocessor_path}\")\n",
    "        \n",
    "        # Lưu cấu hình\n",
    "        config = {\n",
    "            'log_transform': self.log_transform,\n",
    "            'models': list(self.models.keys()),\n",
    "            'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        config_path = os.path.join(model_path, \"config.json\")\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config, f, indent=4)\n",
    "        print(f\"Đã lưu cấu hình vào {config_path}\")\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        \"\"\"\n",
    "        Tải mô hình từ file\n",
    "        \n",
    "        Args:\n",
    "            model_path: Đường dẫn thư mục chứa mô hình đã lưu\n",
    "        \"\"\"\n",
    "        # Tải cấu hình\n",
    "        config_path = os.path.join(model_path, \"config.json\")\n",
    "        if os.path.exists(config_path):\n",
    "            with open(config_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "            self.log_transform = config['log_transform']\n",
    "            model_names = config['models']\n",
    "            \n",
    "            # Tải preprocessor\n",
    "            preprocessor_path = os.path.join(model_path, \"preprocessor.pkl\")\n",
    "            if os.path.exists(preprocessor_path):\n",
    "                self.preprocessor = joblib.load(preprocessor_path)\n",
    "                print(f\"Đã tải bộ tiền xử lý từ {preprocessor_path}\")\n",
    "            \n",
    "            # Tải các mô hình\n",
    "            for name in model_names:\n",
    "                file_path = os.path.join(model_path, f\"{name.replace(' ', '_')}.pkl\")\n",
    "                if os.path.exists(file_path):\n",
    "                    self.models[name] = joblib.load(file_path)\n",
    "                    print(f\"Đã tải mô hình {name} từ {file_path}\")\n",
    "                else:\n",
    "                    print(f\"Không tìm thấy mô hình {name} tại {file_path}\")\n",
    "            \n",
    "            print(f\"Đã tải {len(self.models)} mô hình\")\n",
    "        else:\n",
    "            print(f\"Không tìm thấy file cấu hình tại {config_path}\")\n",
    "\n",
    "# Tạo và lưu mô hình COCOMO II mở rộng\n",
    "if 'pipelines' in model_results:\n",
    "    cocomo_predictor = CocomoIIPredictor()\n",
    "    cocomo_predictor.fit(model_results['pipelines'], preprocessor, log_transform=True)\n",
    "    \n",
    "    # Lưu mô hình\n",
    "    cocomo_predictor.save(os.path.join(OUTPUT_DIR, 'cocomo_ii_extended'))\n",
    "    \n",
    "    # Ví dụ sử dụng mô hình:\n",
    "    # Tạo một mẫu dữ liệu đầu vào\n",
    "    sample_data = X_test.iloc[:5].copy()\n",
    "    \n",
    "    print(\"\\nVí dụ sử dụng mô hình COCOMO II mở rộng:\")\n",
    "    print(\"Dữ liệu đầu vào:\")\n",
    "    print(sample_data)\n",
    "    \n",
    "    results = cocomo_predictor.predict_all(sample_data, model_name='Random Forest (Tuned)')\n",
    "    \n",
    "    print(\"\\nKết quả dự đoán:\")\n",
    "    for i in range(len(sample_data)):\n",
    "        print(f\"\\nMẫu {i+1}:\")\n",
    "        print(f\"  - Effort: {results['effort_pm'][i]:.2f} người-tháng\")\n",
    "        print(f\"  - Thời gian: {results['time_months'][i]:.2f} tháng\")\n",
    "        print(f\"  - Số nhà phát triển: {int(results['developers'][i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d8f76",
   "metadata": {},
   "source": [
    "## 7. Tạo hàm tiện ích cho người dùng\n",
    "\n",
    "Tạo các hàm tiện ích để người dùng có thể sử dụng mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91862877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tiện ích cho người dùng\n",
    "def cocomo_ii_estimate(size, size_type='kloc', model_path=None, model_name='Random Forest (Tuned)'):\n",
    "    \"\"\"\n",
    "    Ước lượng effort, thời gian và kích thước đội ngũ dựa trên kích thước\n",
    "    \n",
    "    Args:\n",
    "        size: Kích thước dự án (KLOC, FP hoặc UCP)\n",
    "        size_type: Loại kích thước ('kloc', 'fp', 'ucp')\n",
    "        model_path: Đường dẫn đến mô hình đã lưu\n",
    "        model_name: Tên mô hình để sử dụng\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary chứa các kết quả dự đoán\n",
    "    \"\"\"\n",
    "    if model_path is None:\n",
    "        model_path = os.path.join(OUTPUT_DIR, 'cocomo_ii_extended')\n",
    "    \n",
    "    # Tải mô hình\n",
    "    cocomo_predictor = CocomoIIPredictor(model_path)\n",
    "    \n",
    "    # Tạo dữ liệu đầu vào\n",
    "    input_data = pd.DataFrame({\n",
    "        'schema': [size_type.upper()],\n",
    "        'size': [size]\n",
    "    })\n",
    "    \n",
    "    # Thêm các cột khác tùy theo loại kích thước\n",
    "    if size_type == 'kloc':\n",
    "        input_data['kloc'] = size\n",
    "        input_data['fp'] = np.nan\n",
    "        input_data['ucp'] = np.nan\n",
    "    elif size_type == 'fp':\n",
    "        input_data['kloc'] = np.nan\n",
    "        input_data['fp'] = size\n",
    "        input_data['ucp'] = np.nan\n",
    "    elif size_type == 'ucp':\n",
    "        input_data['kloc'] = np.nan\n",
    "        input_data['fp'] = np.nan\n",
    "        input_data['ucp'] = size\n",
    "    else:\n",
    "        raise ValueError(\"size_type phải là 'kloc', 'fp', hoặc 'ucp'\")\n",
    "    \n",
    "    # Dự đoán\n",
    "    return cocomo_predictor.predict_all(input_data, model_name)\n",
    "\n",
    "# Tạo giao diện đơn giản để hiển thị kết quả\n",
    "def display_cocomo_ii_results(size, size_type='kloc', model_name='Random Forest (Tuned)'):\n",
    "    \"\"\"\n",
    "    Hiển thị kết quả ước lượng COCOMO II\n",
    "    \n",
    "    Args:\n",
    "        size: Kích thước dự án (KLOC, FP hoặc UCP)\n",
    "        size_type: Loại kích thước ('kloc', 'fp', 'ucp')\n",
    "        model_name: Tên mô hình để sử dụng\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Thực hiện ước lượng\n",
    "        results = cocomo_ii_estimate(size, size_type, model_name=model_name)\n",
    "        \n",
    "        # Hiển thị kết quả\n",
    "        print(f\"\\n--- COCOMO II Estimation Results ---\")\n",
    "        print(f\"Input: {size} {size_type.upper()}\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(\"\\nResults:\")\n",
    "        print(f\"  - Effort: {results['effort_pm'][0]:.2f} person-months\")\n",
    "        print(f\"  - Duration: {results['time_months'][0]:.2f} months\")\n",
    "        print(f\"  - Team Size: {int(results['developers'][0])} developers\")\n",
    "        \n",
    "        # Hiển thị thông báo về chi phí (nếu cần)\n",
    "        rate_per_month = 5000  # Giả định chi phí trung bình mỗi người/tháng\n",
    "        cost = results['effort_pm'][0] * rate_per_month\n",
    "        print(f\"\\nEstimated Cost (at ${rate_per_month}/person-month): ${cost:.2f}\")\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Thử nghiệm với một số ví dụ\n",
    "print(\"\\nThử nghiệm mô hình COCOMO II mở rộng với các ví dụ:\")\n",
    "\n",
    "# Ví dụ với KLOC\n",
    "print(\"\\nVí dụ với KLOC (Kilo Lines of Code):\")\n",
    "display_cocomo_ii_results(10, 'kloc')\n",
    "\n",
    "# Ví dụ với FP\n",
    "print(\"\\nVí dụ với FP (Function Points):\")\n",
    "display_cocomo_ii_results(500, 'fp')\n",
    "\n",
    "# Ví dụ với UCP\n",
    "print(\"\\nVí dụ với UCP (Use Case Points):\")\n",
    "display_cocomo_ii_results(300, 'ucp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868985cf",
   "metadata": {},
   "source": [
    "## 8. Kết luận\n",
    "\n",
    "Trong notebook này, chúng ta đã thực hiện xây dựng một mô hình ước lượng nỗ lực phát triển phần mềm dựa trên COCOMO II sử dụng kết hợp các phương pháp học máy. Chúng ta đã:\n",
    "\n",
    "1. Kết hợp dữ liệu từ 3 schema khác nhau (LOC, FP, UCP)\n",
    "2. Tiền xử lý dữ liệu cho huấn luyện mô hình\n",
    "3. Huấn luyện và đánh giá 3 mô hình:\n",
    "   - Linear Regression (baseline)\n",
    "   - Decision Tree Regressor\n",
    "   - Random Forest Regressor\n",
    "4. Tinh chỉnh các mô hình để cải thiện hiệu suất\n",
    "5. Xây dựng một bộ dự đoán COCOMO II mở rộng\n",
    "6. Xuất mô hình dưới dạng file .pkl để sử dụng trong tương lai\n",
    "\n",
    "Kết quả cho thấy, mô hình Random Forest sau khi tinh chỉnh đạt hiệu suất tốt nhất trong việc dự đoán effort. Mô hình này có thể được sử dụng để ước lượng nỗ lực phát triển phần mềm dựa trên các tham số đầu vào khác nhau như KLOC, FP hoặc UCP."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
