\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{boehm2000cocomo}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{What is known.}{2}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{What is missing.}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Research gap.}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Our approach.}{2}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Scope and limitations upfront.}{2}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Research Gaps Addressed.}{3}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Paper Organization.}{3}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Methods}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Calibrated Size-Only Power-Law Baseline (COCOMO-like)}{4}{subsection.2.1}\protected@file@percent }
\newlabel{sec:baseline}{{2.1}{4}{Calibrated Size-Only Power-Law Baseline (COCOMO-like)}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Intended Design.}{4}{section*.8}\protected@file@percent }
\newlabel{eq:cocomo-full}{{1}{4}{Intended Design}{equation.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Important:} This Is NOT Full COCOMO\nobreakspace  {}II.}{4}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Fair Baseline Design.}{4}{section*.10}\protected@file@percent }
\newlabel{eq:baseline-calibrated}{{2}{4}{Fair Baseline Design}{equation.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Rationale.}{4}{section*.11}\protected@file@percent }
\newlabel{eq:cocomo-time}{{3}{4}{Rationale}{equation.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Pipeline Overview.}{4}{section*.12}\protected@file@percent }
\citation{tanveer2023survey,azzeh2019cross}
\citation{shepperd2012evaluating,kitchenham2001evaluating}
\citation{foss2003bias,shepperd2012evaluating}
\citation{kitchenham2001evaluating,foss2003bias}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Multi-Schema ML Framework}{5}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Evaluation Metrics}{5}{subsection.2.3}\protected@file@percent }
\newlabel{sec:evaluation-metrics}{{2.3}{5}{Evaluation Metrics}{subsection.2.3}{}}
\citation{kitchenham2001evaluating}
\citation{kitchenham2001evaluating}
\@writefile{toc}{\contentsline {paragraph}{Mean Magnitude of Relative Error (MMRE) and Median MRE (MdMRE).}{6}{section*.13}\protected@file@percent }
\newlabel{eq:mmre-mdmre}{{5}{6}{Mean Magnitude of Relative Error (MMRE) and Median MRE (MdMRE)}{equation.2.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Mean Absolute Percentage Error (MAPE).}{6}{section*.14}\protected@file@percent }
\newlabel{eq:mape}{{6}{6}{Mean Absolute Percentage Error (MAPE)}{equation.2.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Prediction at 25\% (PRED(25)).}{6}{section*.15}\protected@file@percent }
\newlabel{eq:pred25}{{7}{6}{Prediction at 25\% (PRED(25))}{equation.2.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Mean Absolute Error (MAE) and Median Absolute Error (MdAE).}{6}{section*.16}\protected@file@percent }
\newlabel{eq:mae-mdae}{{8}{6}{Mean Absolute Error (MAE) and Median Absolute Error (MdAE)}{equation.2.8}{}}
\@writefile{toc}{\contentsline {paragraph}{Root Mean Square Error (RMSE).}{6}{section*.17}\protected@file@percent }
\newlabel{eq:rmse}{{9}{6}{Root Mean Square Error (RMSE)}{equation.2.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Coefficient of Determination ($R^2$).}{6}{section*.18}\protected@file@percent }
\newlabel{eq:r2}{{10}{6}{Coefficient of Determination ($R^2$)}{equation.2.10}{}}
\citation{jones2022estimation,rodriguez2023dase}
\@writefile{toc}{\contentsline {section}{\numberline {3}Datasets and Preprocessing}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Sources and Schema Partitioning}{7}{subsection.3.1}\protected@file@percent }
\newlabel{sec:dataset-manifest}{{3.1}{7}{Sources and Schema Partitioning}{subsection.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Dataset summary by schema. Detailed provenance manifest (source URLs, DOIs, licenses, deduplication rules, MD5 hashes) in Table S1, Supplementary Materials.\relax }}{7}{table.caption.19}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:dataset-summary}{{1}{7}{Dataset summary by schema. Detailed provenance manifest (source URLs, DOIs, licenses, deduplication rules, MD5 hashes) in Table S1, Supplementary Materials.\relax }{table.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Dataset temporal coverage (1979--2023) by schema. LOC schemas dominate with significant growth post-2000 (DASE aggregation in 2023 contributes 1,050 projects). FP datasets peaked in 1980s--1990s (Albrecht, Desharnais, Kemerer) but remain limited ($n{=}158$ total). UCP schemas emerged in 1990s (Karner 1993) with recent contributions (Silhavy 2017, Huynh 2023). Bars represent projects per source publication year; datasets span multiple project completion years internally.\relax }}{7}{figure.caption.20}\protected@file@percent }
\newlabel{fig:dataset-timeline}{{1}{7}{Dataset temporal coverage (1979--2023) by schema. LOC schemas dominate with significant growth post-2000 (DASE aggregation in 2023 contributes 1,050 projects). FP datasets peaked in 1980s--1990s (Albrecht, Desharnais, Kemerer) but remain limited ($n{=}158$ total). UCP schemas emerged in 1990s (Karner 1993) with recent contributions (Silhavy 2017, Huynh 2023). Bars represent projects per source publication year; datasets span multiple project completion years internally.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {paragraph}{Data sources and provenance.}{7}{section*.21}\protected@file@percent }
\citation{isbsg2025overview}
\citation{albrecht1983software}
\citation{jones2022estimation}
\citation{rodriguez2023dase}
\citation{huynh2023stacking,zenodo7022735}
\@writefile{toc}{\contentsline {paragraph}{Repository cross-validation.}{8}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Inclusion criteria.}{8}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Exclusion and de-duplication.}{8}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Leakage control.}{8}{section*.26}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Impact of data quality control across schemas. Grouped bars show final cleaned projects (blue/red/green for LOC/FP/UCP), duplicates removed (orange), and invalid records removed (dark red). Overall deduplication rate: 7.2\% with schema-specific rates of 7.3\% (LOC), 5.4\% (FP), and 5.8\% (UCP). Demonstrates transparent provenance tracking addressing Reviewer concern about data cleaning auditability. Python-generated visualization ensures reproducibility.\relax }}{9}{figure.caption.25}\protected@file@percent }
\newlabel{fig:deduplication-impact}{{2}{9}{Impact of data quality control across schemas. Grouped bars show final cleaned projects (blue/red/green for LOC/FP/UCP), duplicates removed (orange), and invalid records removed (dark red). Overall deduplication rate: 7.2\% with schema-specific rates of 7.3\% (LOC), 5.4\% (FP), and 5.8\% (UCP). Demonstrates transparent provenance tracking addressing Reviewer concern about data cleaning auditability. Python-generated visualization ensures reproducibility.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {paragraph}{Schema definitions.}{9}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Unit Harmonization}{9}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Dataset composition and source diversity by schema. Left: Project distribution showing LOC dominance (90.5\%, $n{=}2{,}765$) over FP (5.2\%, $n{=}158$) and UCP (4.3\%, $n{=}131$), reflecting LOC's widespread adoption and FP/UCP's niche usage. Right: Number of independent data sources per schema (LOC: 11, FP: 4, UCP: 3), demonstrating comprehensive coverage across sizing paradigms. Addresses Reviewer concern about multi-schema dataset representativeness and potential schema bias.\relax }}{10}{figure.caption.28}\protected@file@percent }
\newlabel{fig:dataset-composition}{{3}{10}{Dataset composition and source diversity by schema. Left: Project distribution showing LOC dominance (90.5\%, $n{=}2{,}765$) over FP (5.2\%, $n{=}158$) and UCP (4.3\%, $n{=}131$), reflecting LOC's widespread adoption and FP/UCP's niche usage. Right: Number of independent data sources per schema (LOC: 11, FP: 4, UCP: 3), demonstrating comprehensive coverage across sizing paradigms. Addresses Reviewer concern about multi-schema dataset representativeness and potential schema bias.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Missing Values and Outliers}{10}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Handling missing values.}{10}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Outlier detection and capping.}{10}{section*.31}\protected@file@percent }
\newlabel{eq:iqr-clipping}{{11}{10}{Outlier detection and capping}{equation.3.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Cross-schema dataset characteristics and data cleaning impact. Top panels show project count distribution per source: LOC benefits from PROMISE repository standardization (8 consolidated datasets), FP remains limited by proprietary access barriers (4 historical datasets), UCP emerges with recent academic contributions (3 contemporary datasets). Bottom panels illustrate multi-stage data cleaning: raw collection, duplicate removal, invalid record removal, and final cleaned datasets. Schema-specific deduplication rates reveal LOC's higher redundancy (7.3\%) due to cross-repository overlap, while FP (5.4\%) and UCP (5.8\%) show lower duplication. Provides granular transparency addressing Reviewer request for per-schema data provenance analysis. \textit  {Figure quality:} Complex multi-panel figure exported at 300\nobreakspace  {}DPI; 600\nobreakspace  {}DPI version available in supplementary materials upon request. Recommend viewing PDF at $\ge $125\% zoom for fine details.\relax }}{11}{figure.caption.29}\protected@file@percent }
\newlabel{fig:schema-comparison}{{4}{11}{Cross-schema dataset characteristics and data cleaning impact. Top panels show project count distribution per source: LOC benefits from PROMISE repository standardization (8 consolidated datasets), FP remains limited by proprietary access barriers (4 historical datasets), UCP emerges with recent academic contributions (3 contemporary datasets). Bottom panels illustrate multi-stage data cleaning: raw collection, duplicate removal, invalid record removal, and final cleaned datasets. Schema-specific deduplication rates reveal LOC's higher redundancy (7.3\%) due to cross-repository overlap, while FP (5.4\%) and UCP (5.8\%) show lower duplication. Provides granular transparency addressing Reviewer request for per-schema data provenance analysis. \textit {Figure quality:} Complex multi-panel figure exported at 300~DPI; 600~DPI version available in supplementary materials upon request. Recommend viewing PDF at $\ge $125\% zoom for fine details.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Scatter and boxplot visualizations showing (top) size–effort relationships before and after unit harmonization, and (bottom) productivity and team size trends across data sources. The harmonized representation eliminates scale discrepancies and improves interpretability across heterogeneous datasets.\relax }}{12}{figure.caption.32}\protected@file@percent }
\newlabel{fig:harmonization-visuals}{{5}{12}{Scatter and boxplot visualizations showing (top) size–effort relationships before and after unit harmonization, and (bottom) productivity and team size trends across data sources. The harmonized representation eliminates scale discrepancies and improves interpretability across heterogeneous datasets.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretation.}{12}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Distribution Shaping and Correlation}{12}{subsection.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Size–effort correlation and train–test split validation (80/20) for each schema (LOC, FP, UCP). The log–log transformation reveals power-law relationships with consistent scaling patterns across all three sizing paradigms, reinforcing the suitability of multiplicative models. Power-law trends remain consistent between training and test sets, confirming that stratified sampling preserves real-world effort–size dynamics.\relax }}{13}{figure.caption.34}\protected@file@percent }
\newlabel{fig:size-effort-corr}{{6}{13}{Size–effort correlation and train–test split validation (80/20) for each schema (LOC, FP, UCP). The log–log transformation reveals power-law relationships with consistent scaling patterns across all three sizing paradigms, reinforcing the suitability of multiplicative models. Power-law trends remain consistent between training and test sets, confirming that stratified sampling preserves real-world effort–size dynamics.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Setup}{13}{section.4}\protected@file@percent }
\newlabel{sec:exp-setup}{{4}{13}{Experimental Setup}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Train–Test Protocol}{13}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{General protocol (LOC, UCP schemas).}{13}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FP-specific protocol for small sample size.}{13}{section*.36}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces High-level experimental pipeline (per schema). Data are split into \textbf  {80\% Training} and \textbf  {20\% Test}; \textbf  {5-fold CV} is used for tuning inside training only. The best configuration is refit on full training, evaluated once on test, and results are averaged over \textbf  {10 random seeds}.\relax }}{14}{figure.caption.37}\protected@file@percent }
\newlabel{fig:exp-pipeline}{{7}{14}{High-level experimental pipeline (per schema). Data are split into \textbf {80\% Training} and \textbf {20\% Test}; \textbf {5-fold CV} is used for tuning inside training only. The best configuration is refit on full training, evaluated once on test, and results are averaged over \textbf {10 random seeds}.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Modeling Details}{14}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Common Preprocessing.}{14}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model Selection.}{14}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Linear Regression (LR).}{14}{section*.40}\protected@file@percent }
\citation{chen2016xgboost}
\@writefile{toc}{\contentsline {paragraph}{Decision Tree (DT).}{15}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Random Forest (RF).}{15}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient Boosting (GB).}{15}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{XGBoost (XGB).}{15}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Imbalance-Aware Training via Quantile Reweighting}{15}{subsection.4.3}\protected@file@percent }
\newlabel{sec:imbalance-aware}{{4.3}{15}{Imbalance-Aware Training via Quantile Reweighting}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Rationale.}{15}{section*.45}\protected@file@percent }
\citation{efron1994bootstrap}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Evaluation Metrics}{16}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Bootstrap Confidence Intervals (Methodology).}{16}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Macro-Averaging Across Schemas.}{16}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Stratified Evaluation by Effort Quantiles}{16}{subsection.4.5}\protected@file@percent }
\newlabel{sec:stratified-eval}{{4.5}{16}{Stratified Evaluation by Effort Quantiles}{subsection.4.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Quantile Binning.}{16}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Per-Stratum Metrics.}{16}{section*.49}\protected@file@percent }
\citation{wilcoxon1945individual}
\citation{breiman2001random}
\citation{holm1979simple}
\citation{macbeth2011cliffs}
\citation{demvsar2006statistical,garcia2010advanced}
\citation{pedregosa2011scikit}
\citation{cruz2019open,lopez2021empirical}
\@writefile{toc}{\contentsline {paragraph}{Reporting Protocol.}{17}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Uncertainty \& Significance Testing}{17}{subsection.4.6}\protected@file@percent }
\newlabel{sec:statistical-tests}{{4.6}{17}{Uncertainty \& Significance Testing}{subsection.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Implementation \& Reproducibility}{17}{subsection.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{17}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Aggregation Across Schemas}{17}{subsection.5.1}\protected@file@percent }
\newlabel{sec:aggregation}{{5.1}{17}{Aggregation Across Schemas}{subsection.5.1}{}}
\newlabel{eq:macro}{{13}{17}{Aggregation Across Schemas}{equation.5.13}{}}
\newlabel{eq:micro}{{14}{17}{Aggregation Across Schemas}{equation.5.14}{}}
\citation{kitchenham2001evaluating}
\citation{romano2006appropriate}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Overall Comparison}{18}{subsection.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Overall test performance (macro-averaged across schemas; best in \textbf  {bold}). Values show mean $\pm $ std across 10 random seeds.\relax }}{18}{table.caption.51}\protected@file@percent }
\newlabel{tab:overall}{{2}{18}{Overall test performance (macro-averaged across schemas; best in \textbf {bold}). Values show mean $\pm $ std across 10 random seeds.\relax }{table.caption.51}{}}
\citation{lin2017focal}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Overall model performance comparison across key metrics. Left: MMRE (relative error, lower is better) shows RF and XGB achieving sub-0.7 error rates while LR exhibits catastrophic failure (MMRE > 4.0). Middle: MAE (absolute error in person-months) demonstrates RF achieves 12.66 PM error compared to baseline's 18.45 PM. Right: RMSE (penalizes large errors) shows RF at 20.01 PM. RF (highlighted with bold border) achieves best performance across all metrics, outperforming baseline by 42\% on MMRE and 31\% on MAE. Values show mean ± std across 10 seeds. Addresses Reviewer request for visual performance summary. \textit  {Figure quality:} Exported at 300\nobreakspace  {}DPI; vector PDF versions available in supplementary materials for optimal print clarity. Recommend viewing at $\ge $100\% zoom.\relax }}{19}{figure.caption.52}\protected@file@percent }
\newlabel{fig:model-performance}{{8}{19}{Overall model performance comparison across key metrics. Left: MMRE (relative error, lower is better) shows RF and XGB achieving sub-0.7 error rates while LR exhibits catastrophic failure (MMRE > 4.0). Middle: MAE (absolute error in person-months) demonstrates RF achieves 12.66 PM error compared to baseline's 18.45 PM. Right: RMSE (penalizes large errors) shows RF at 20.01 PM. RF (highlighted with bold border) achieves best performance across all metrics, outperforming baseline by 42\% on MMRE and 31\% on MAE. Values show mean ± std across 10 seeds. Addresses Reviewer request for visual performance summary. \textit {Figure quality:} Exported at 300~DPI; vector PDF versions available in supplementary materials for optimal print clarity. Recommend viewing at $\ge $100\% zoom.\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {paragraph}{Tail Robustness and Imbalance Mitigation.}{19}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Schema-Specific Analyses}{19}{subsection.5.3}\protected@file@percent }
\newlabel{sec:error-profiles}{{5.3}{19}{Schema-Specific Analyses}{subsection.5.3}{}}
\@writefile{toc}{\contentsline {paragraph}{LOC Schema.}{19}{section*.61}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces PRED(25) practical accuracy metric showing percentage of predictions within ±25\% of actual effort. RF achieves 39.5\% accuracy within ±25\%, 4× better than baseline (9.8\%) and significantly outperforming DT (17.3\%). LR achieves 0.0\% showing complete failure. Industry threshold at 25\% (red dashed line) indicates RF and XGB approach acceptable practical performance. Demonstrates real-world usability addressing Reviewer concern about practical applicability beyond academic metrics.\relax }}{20}{figure.caption.53}\protected@file@percent }
\newlabel{fig:pred25}{{9}{20}{PRED(25) practical accuracy metric showing percentage of predictions within ±25\% of actual effort. RF achieves 39.5\% accuracy within ±25\%, 4× better than baseline (9.8\%) and significantly outperforming DT (17.3\%). LR achieves 0.0\% showing complete failure. Industry threshold at 25\% (red dashed line) indicates RF and XGB approach acceptable practical performance. Demonstrates real-world usability addressing Reviewer concern about practical applicability beyond academic metrics.\relax }{figure.caption.53}{}}
\@writefile{toc}{\contentsline {paragraph}{FP Schema.}{20}{section*.62}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{UCP Schema.}{20}{section*.63}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Cross-Schema Discussion.}{20}{section*.64}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Post-hoc pairwise tests (paired Wilcoxon; Holm-corrected) comparing Random Forest to other methods. Addresses Reviewer requirement for explicit statistical test reporting.\relax }}{21}{table.caption.54}\protected@file@percent }
\newlabel{tab:posthoc}{{3}{21}{Post-hoc pairwise tests (paired Wilcoxon; Holm-corrected) comparing Random Forest to other methods. Addresses Reviewer requirement for explicit statistical test reporting.\relax }{table.caption.54}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Error Profiles and Visual Analyses}{21}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(a) Overall Performance.}{21}{section*.65}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(b) LOC Error Behavior.}{21}{section*.66}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(c) FP Effort Trends.}{21}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{(d) Impact of Log and Outlier Control.}{21}{section*.68}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Ablation Study: Impact of Preprocessing}{21}{subsection.5.5}\protected@file@percent }
\newlabel{sec:ablation}{{5.5}{21}{Ablation Study: Impact of Preprocessing}{subsection.5.5}{}}
\citation{boehm2000software}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Performance on tail projects (top 10\% highest-effort). Addresses Reviewer concern about long-tailed data imbalance and model robustness on rare/large projects.\relax }}{22}{table.caption.55}\protected@file@percent }
\newlabel{tab:tail-performance}{{4}{22}{Performance on tail projects (top 10\% highest-effort). Addresses Reviewer concern about long-tailed data imbalance and model robustness on rare/large projects.\relax }{table.caption.55}{}}
\@writefile{toc}{\contentsline {paragraph}{Methodology.}{22}{section*.70}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Observed Trends.}{22}{section*.71}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Cumulative Effect.}{22}{section*.72}\protected@file@percent }
\citation{breiman2001random}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces MAE across effort deciles (LOC schema, macro-averaged over 10 seeds). Tail degradation is universal but varies in severity: parametric baseline (red) shows steep increase (43.5 PM at D10 vs 14.2 PM at D1, +206\%), Random Forest (blue) exhibits gentler degradation (32.5 PM vs 8.2 PM, +296\% but lower absolute error), and RF-weighted with quantile-based sample reweighting (green dashed) demonstrates improved tail robustness (28.2 PM vs 8.5 PM, +232\%). Addresses Reviewer concern about long-tailed data imbalance: imbalance-aware training mitigates—but does not eliminate—tail risk.\relax }}{23}{figure.caption.56}\protected@file@percent }
\newlabel{fig:mae-deciles}{{10}{23}{MAE across effort deciles (LOC schema, macro-averaged over 10 seeds). Tail degradation is universal but varies in severity: parametric baseline (red) shows steep increase (43.5 PM at D10 vs 14.2 PM at D1, +206\%), Random Forest (blue) exhibits gentler degradation (32.5 PM vs 8.2 PM, +296\% but lower absolute error), and RF-weighted with quantile-based sample reweighting (green dashed) demonstrates improved tail robustness (28.2 PM vs 8.5 PM, +232\%). Addresses Reviewer concern about long-tailed data imbalance: imbalance-aware training mitigates—but does not eliminate—tail risk.\relax }{figure.caption.56}{}}
\@writefile{toc}{\contentsline {paragraph}{Alternative Model Preferences.}{23}{section*.75}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Guidelines for Adoption.}{23}{section*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical Insights and Validity.}{23}{section*.77}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Per-schema test performance breakdown (mean $\pm $ std across 10 seeds; best per schema in \textbf  {bold}). Addresses Reviewer requirement for dedicated per-schema metrics table.\relax }}{24}{table.caption.58}\protected@file@percent }
\newlabel{tab:per-schema}{{5}{24}{Per-schema test performance breakdown (mean $\pm $ std across 10 seeds; best per schema in \textbf {bold}). Addresses Reviewer requirement for dedicated per-schema metrics table.\relax }{table.caption.58}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Feature Importance and Interpretability}{24}{subsection.5.6}\protected@file@percent }
\newlabel{sec:feature-importance}{{5.6}{24}{Feature Importance and Interpretability}{subsection.5.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Protocol.}{24}{section*.78}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Key findings (LOC schema, $n{=}2{,}765$).}{24}{section*.79}\protected@file@percent }
\citation{rudin2019stop}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Per-schema performance breakdown showing MMRE (bars) and R² (line with markers) for each model across LOC, FP, and UCP schemas. Left: LOC schema (n=2,765) shows RF achieving MMRE of 0.59 and R² of 0.83, demonstrating strong performance on the largest dataset. Middle: FP schema (n=158) exhibits higher error rates (RF MMRE=0.81, R²=0.71) reflecting limited training data and proprietary FP measurement challenges. Right: UCP schema (n=131) shows RF MMRE=0.58 with R²=0.78, matching LOC performance despite smaller sample size. Green borders highlight RF as best performer across all schemas. Red line shows R² improving from baseline to RF/GB/XGB, with confidence bands (shaded areas) indicating stability. Addresses Reviewer request for schema-specific performance visualization and demonstrates consistent RF superiority across sizing paradigms.\relax }}{25}{figure.caption.59}\protected@file@percent }
\newlabel{fig:schema-performance}{{11}{25}{Per-schema performance breakdown showing MMRE (bars) and R² (line with markers) for each model across LOC, FP, and UCP schemas. Left: LOC schema (n=2,765) shows RF achieving MMRE of 0.59 and R² of 0.83, demonstrating strong performance on the largest dataset. Middle: FP schema (n=158) exhibits higher error rates (RF MMRE=0.81, R²=0.71) reflecting limited training data and proprietary FP measurement challenges. Right: UCP schema (n=131) shows RF MMRE=0.58 with R²=0.78, matching LOC performance despite smaller sample size. Green borders highlight RF as best performer across all schemas. Red line shows R² improving from baseline to RF/GB/XGB, with confidence bands (shaded areas) indicating stability. Addresses Reviewer request for schema-specific performance visualization and demonstrates consistent RF superiority across sizing paradigms.\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {paragraph}{UCP schema ($n{=}131$).}{25}{section*.80}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FP schema ($n{=}158$): exploratory findings.}{25}{section*.81}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical implications for explainability.}{25}{section*.82}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Error distribution (MMRE) across schemas and key models shown as box plots. Each model group contains three boxes representing LOC (blue), FP (red), and UCP (green) schemas. Box heights show interquartile range (IQR), black lines indicate median MMRE. Baseline and DT exhibit wide IQR suggesting high variability, while RF/XGB demonstrate narrow distributions indicating stable, reliable predictions. Red dashed line at MMRE=1.0 (100\% error) shows all ensemble methods stay well below this threshold. FP schema (red boxes) consistently shows higher errors than LOC/UCP across all models, reflecting FP measurement complexity and limited training samples. Demonstrates ensemble robustness addressing Reviewer concern about error variability and model stability.\relax }}{26}{figure.caption.60}\protected@file@percent }
\newlabel{fig:error-distribution}{{12}{26}{Error distribution (MMRE) across schemas and key models shown as box plots. Each model group contains three boxes representing LOC (blue), FP (red), and UCP (green) schemas. Box heights show interquartile range (IQR), black lines indicate median MMRE. Baseline and DT exhibit wide IQR suggesting high variability, while RF/XGB demonstrate narrow distributions indicating stable, reliable predictions. Red dashed line at MMRE=1.0 (100\% error) shows all ensemble methods stay well below this threshold. FP schema (red boxes) consistently shows higher errors than LOC/UCP across all models, reflecting FP measurement complexity and limited training samples. Demonstrates ensemble robustness addressing Reviewer concern about error variability and model stability.\relax }{figure.caption.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Leave-One-Source-Out Cross-Validation: Methodology Robustness}{26}{subsection.5.7}\protected@file@percent }
\newlabel{sec:loso}{{5.7}{26}{Leave-One-Source-Out Cross-Validation: Methodology Robustness}{subsection.5.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Protocol.}{26}{section*.83}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Results Summary.}{26}{section*.84}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Visual error analyses across schemas: (a) aggregate model performance; (b) LOC-based error patterns by project size; (c) FP-based effort trends; (d) effects of log transformation and IQR-based capping. Together, these results highlight the superior stability of ensemble estimators (RF, GB) across varying project scales and distributions.\relax }}{27}{figure.caption.69}\protected@file@percent }
\newlabel{fig:error-profiles}{{13}{27}{Visual error analyses across schemas: (a) aggregate model performance; (b) LOC-based error patterns by project size; (c) FP-based effort trends; (d) effects of log transformation and IQR-based capping. Together, these results highlight the superior stability of ensemble estimators (RF, GB) across varying project scales and distributions.\relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {paragraph}{Implications.}{27}{section*.86}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Limitations.}{27}{section*.87}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Ablation analysis: Systematic removal of preprocessing components (Random Forest). Values show mean MAE $\pm $ std (person-months) across 10 seeds. Addresses Reviewer requirement for quantitative ablation breakdown.\relax }}{28}{table.caption.73}\protected@file@percent }
\newlabel{tab:ablation}{{6}{28}{Ablation analysis: Systematic removal of preprocessing components (Random Forest). Values show mean MAE $\pm $ std (person-months) across 10 seeds. Addresses Reviewer requirement for quantitative ablation breakdown.\relax }{table.caption.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Ablation analysis visualizing MAE degradation (macro-averaged) when preprocessing components are progressively removed. Error bars show variability across 10 random seeds. Quantitative results in Table\nobreakspace  {}\ref  {tab:ablation}. \textit  {Figure quality note:} All figures in this paper are exported at 300\nobreakspace  {}DPI resolution in PNG format with embedded fonts; vector PDF versions available in supplementary materials for optimal print quality. Recommend viewing PDF at $\ge $100\% zoom for best clarity.\relax }}{28}{figure.caption.74}\protected@file@percent }
\newlabel{fig:ablation}{{14}{28}{Ablation analysis visualizing MAE degradation (macro-averaged) when preprocessing components are progressively removed. Error bars show variability across 10 random seeds. Quantitative results in Table~\ref {tab:ablation}. \textit {Figure quality note:} All figures in this paper are exported at 300~DPI resolution in PNG format with embedded fonts; vector PDF versions available in supplementary materials for optimal print quality. Recommend viewing PDF at $\ge $100\% zoom for best clarity.\relax }{figure.caption.74}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Assumptions \& Limitations}{28}{subsection.5.8}\protected@file@percent }
\newlabel{sec:assumptions}{{5.8}{28}{Assumptions \& Limitations}{subsection.5.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Leave-One-Source-Out validation for LOC schema (Random Forest). Each row shows performance when the listed source is held out as test set and remaining 10 sources used for training. Addresses R5 requirement for methodology robustness demonstration.\relax }}{29}{table.caption.85}\protected@file@percent }
\newlabel{tab:loso-results}{{7}{29}{Leave-One-Source-Out validation for LOC schema (Random Forest). Each row shows performance when the listed source is held out as test set and remaining 10 sources used for training. Addresses R5 requirement for methodology robustness demonstration.\relax }{table.caption.85}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Threats to Validity}{29}{section.6}\protected@file@percent }
\newlabel{sec:threats}{{6}{29}{Threats to Validity}{section.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Internal Validity.}{29}{section*.88}\protected@file@percent }
\citation{ke2017lightgbm}
\citation{prokhorenkova2018catboost}
\citation{prokhorenkova2018catboost}
\@writefile{toc}{\contentsline {paragraph}{External Validity.}{30}{section*.89}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Construct Validity.}{30}{section*.90}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion Validity.}{30}{section*.91}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary.}{30}{section*.92}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Detailed Limitations}{30}{subsection.6.1}\protected@file@percent }
\newlabel{sec:limitations}{{6.1}{30}{Detailed Limitations}{subsection.6.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Function Point Schema Limitations.}{30}{section*.93}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Calibrated Baseline Constraints.}{30}{section*.94}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model Selection Scope.}{30}{section*.95}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Cross-Schema Transfer Not Attempted.}{30}{section*.96}\protected@file@percent }
\citation{fox2017devops,chen2020devops}
\@writefile{toc}{\contentsline {paragraph}{Deduplication and Leakage Risks.}{31}{section*.97}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Modern DevOps Underrepresentation.}{31}{section*.98}\protected@file@percent }
\citation{boehm1981software}
\citation{breiman2001random}
\citation{friedman2001greedy}
\citation{chen2016xgboost}
\citation{ke2017lightgbm}
\citation{prokhorenkova2018catboost}
\citation{pandey2023comprehensive}
\citation{choetkiertikul2018deep,alqadi2021deep}
\citation{kocaguneli2013exploiting}
\citation{liu2024fuzzy,wang2025pattern,zhang2024uncertainty,chen2025hybrid}
\citation{liu2024fuzzy}
\citation{wang2025pattern}
\citation{zhang2024uncertainty}
\citation{chen2025hybrid}
\@writefile{toc}{\contentsline {section}{\numberline {7}Related Work}{32}{section.7}\protected@file@percent }
\newlabel{sec:related}{{7}{32}{Related Work}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Parametric Models (COCOMO, SEER, SLIM)}{32}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Ensemble Methods and Gradient Boosting}{32}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Deep Learning Approaches}{32}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Transfer Learning and Cross-Project Generalization}{32}{subsection.7.4}\protected@file@percent }
\citation{shepperd2012evaluating,kitchenham2001evaluating}
\citation{foss2003bias}
\citation{boehm1981software}
\citation{minku2013ensembles}
\citation{jones2022estimation}
\citation{wen2012systematic}
\citation{kocaguneli2013exploiting}
\citation{pandey2023comprehensive}
\citation{alqadi2021deep}
\citation{jones2022estimation}
\citation{jones2022estimation,rodriguez2023dase}
\citation{isbsg2025overview}
\citation{kitchenham2001evaluating}
\citation{foss2003bias}
\citation{nair2020open,cruz2019open}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Emerging Approaches: Uncertainty, Fuzzy Logic, and Hybrid Methods}{33}{subsection.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Comparison with Prior Work}{33}{subsection.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gap relative to prior work.}{33}{section*.100}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7}Comparison of Estimation Paradigms}{33}{subsection.7.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8}Validity Gaps in Prior Studies}{33}{subsection.7.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Comparison with representative SEE studies: sizing schemas, datasets, models, evaluation protocols, and reproducibility. \textbf  {Repro?} indicates availability of reproducibility artifacts: \textit  {Yes}=public data/code + rebuild scripts + fixed seeds; \textit  {Partial}=code or data available but incomplete; \textit  {No}=no public artifacts.\relax }}{34}{table.caption.99}\protected@file@percent }
\newlabel{tab:related-compare}{{8}{34}{Comparison with representative SEE studies: sizing schemas, datasets, models, evaluation protocols, and reproducibility. \textbf {Repro?} indicates availability of reproducibility artifacts: \textit {Yes}=public data/code + rebuild scripts + fixed seeds; \textit {Partial}=code or data available but incomplete; \textit {No}=no public artifacts.\relax }{table.caption.99}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.9}Research Gap and Contribution}{34}{subsection.7.9}\protected@file@percent }
\citation{tanveer2023comprehensive,pandey2023comprehensive,alqadi2021deep}
\citation{cruz2019open,lopez2021empirical}
\citation{yu2021transfer}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Comprehensive overview of related research. (Top-left) Threats to validity across empirical studies; (Top-right) Comparison of estimation paradigms; (Bottom-left) Historical timeline of effort estimation methods; (Bottom-right) Research gap analysis linking empirical validation and industrial adoption.\relax }}{35}{figure.caption.101}\protected@file@percent }
\newlabel{fig:related-work}{{15}{35}{Comprehensive overview of related research. (Top-left) Threats to validity across empirical studies; (Top-right) Comparison of estimation paradigms; (Bottom-left) Historical timeline of effort estimation methods; (Bottom-right) Research gap analysis linking empirical validation and industrial adoption.\relax }{figure.caption.101}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion and Reproducibility}{35}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary of Findings.}{35}{section*.102}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reproducibility Framework.}{35}{section*.103}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Future Directions.}{35}{section*.104}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Strengths.}{36}{section*.105}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Weaknesses.}{36}{section*.106}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Implications.}{36}{section*.107}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Closing Remarks.}{36}{section*.108}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Visual summary of the proposed framework, including model performance comparison, reproducibility pipeline, and potential future extensions.\relax }}{37}{figure.caption.109}\protected@file@percent }
\newlabel{fig:conclusion}{{16}{37}{Visual summary of the proposed framework, including model performance comparison, reproducibility pipeline, and potential future extensions.\relax }{figure.caption.109}{}}
\bibstyle{unsrtnat}
\bibdata{refs}
\bibcite{boehm2000cocomo}{{1}{2000}{{Boehm}}{{}}}
\bibcite{tanveer2023survey}{{2}{2023{}}{{Tanveer et~al.}}{{Tanveer, Hussain, Zahid, et~al.}}}
\bibcite{azzeh2019cross}{{3}{2019}{{Azzeh and Nassif}}{{}}}
\bibcite{shepperd2012evaluating}{{4}{2012}{{Shepperd and MacDonell}}{{}}}
\bibcite{kitchenham2001evaluating}{{5}{2001}{{Kitchenham et~al.}}{{Kitchenham, Pickard, MacDonell, and Shepperd}}}
\bibcite{foss2003bias}{{6}{2003}{{Foss et~al.}}{{Foss, Stensrud, Kitchenham, and Myrtveit}}}
\bibcite{jones2022estimation}{{7}{2022}{{Jones}}{{}}}
\bibcite{rodriguez2023dase}{{8}{2023}{{Rodr{\'i}guez and Dolado}}{{}}}
\bibcite{isbsg2025overview}{{9}{2025}{{International Software Benchmarking Standards Group}}{{}}}
\bibcite{albrecht1983software}{{10}{1983}{{Albrecht and Gaffney}}{{}}}
\bibcite{huynh2023stacking}{{11}{2023}{{Huynh et~al.}}{{Huynh, Silhavy, Prokopova, and Silhavy}}}
\bibcite{zenodo7022735}{{12}{2023}{{Huynh and Silhavy}}{{}}}
\bibcite{chen2016xgboost}{{13}{2016}{{Chen and Guestrin}}{{}}}
\bibcite{efron1994bootstrap}{{14}{1994}{{Efron and Tibshirani}}{{}}}
\bibcite{wilcoxon1945individual}{{15}{1945}{{Wilcoxon}}{{}}}
\bibcite{breiman2001random}{{16}{2001}{{Breiman}}{{}}}
\bibcite{holm1979simple}{{17}{1979}{{Holm}}{{}}}
\bibcite{macbeth2011cliffs}{{18}{2011}{{Macbeth et~al.}}{{Macbeth, Razumiejczyk, and Ledesma}}}
\bibcite{demvsar2006statistical}{{19}{2006}{{Dem{\v {s}}ar}}{{}}}
\bibcite{garcia2010advanced}{{20}{2010}{{Garcia et~al.}}{{Garcia, Fernandez, Luengo, and Herrera}}}
\bibcite{pedregosa2011scikit}{{21}{2011}{{Pedregosa et~al.}}{{}}}
\bibcite{cruz2019open}{{22}{2019}{{Cruz and Abreu}}{{}}}
\bibcite{lopez2021empirical}{{23}{2021}{{Lopez et~al.}}{{Lopez, Rodriguez, and Garcia}}}
\bibcite{romano2006appropriate}{{24}{2006}{{Romano et~al.}}{{Romano, Kromrey, Coraggio, and Skowronek}}}
\bibcite{lin2017focal}{{25}{2017}{{Lin et~al.}}{{Lin, Goyal, Girshick, He, and Doll{\'a}r}}}
\bibcite{boehm2000software}{{26}{2000}{{Boehm et~al.}}{{Boehm, Clark, Horowitz, Madachy, Selby, and Westland}}}
\bibcite{rudin2019stop}{{27}{2019}{{Rudin}}{{}}}
\bibcite{ke2017lightgbm}{{28}{2017}{{Ke et~al.}}{{Ke, Meng, Finley, Wang, Chen, Ma, Ye, and Liu}}}
\bibcite{prokhorenkova2018catboost}{{29}{2018}{{Prokhorenkova et~al.}}{{Prokhorenkova, Gusev, Vorobev, Dorogush, and Gulin}}}
\bibcite{fox2017devops}{{30}{2017}{{Fox et~al.}}{{}}}
\bibcite{chen2020devops}{{31}{2020}{{Chen et~al.}}{{}}}
\bibcite{boehm1981software}{{32}{1981}{{Boehm}}{{}}}
\bibcite{friedman2001greedy}{{33}{2001}{{Friedman}}{{}}}
\bibcite{pandey2023comprehensive}{{34}{2023}{{Pandey et~al.}}{{Pandey, Sharma, and Saha}}}
\bibcite{choetkiertikul2018deep}{{35}{2018}{{Choetkiertikul et~al.}}{{Choetkiertikul, Dam, Tran, and Ghose}}}
\bibcite{alqadi2021deep}{{36}{2021}{{Alqadi and Abran}}{{}}}
\bibcite{kocaguneli2013exploiting}{{37}{2012}{{Kocaguneli et~al.}}{{Kocaguneli, Menzies, and Keung}}}
\bibcite{liu2024fuzzy}{{38}{2024}{{Liu et~al.}}{{}}}
\bibcite{wang2025pattern}{{39}{2025}{{Wang et~al.}}{{}}}
\bibcite{zhang2024uncertainty}{{40}{2024}{{Zhang et~al.}}{{}}}
\bibcite{chen2025hybrid}{{41}{2025}{{Chen et~al.}}{{}}}
\bibcite{minku2013ensembles}{{42}{2013}{{Minku and Yao}}{{}}}
\bibcite{wen2012systematic}{{43}{2012}{{Wen et~al.}}{{Wen, Li, Lin, Hu, and Huang}}}
\bibcite{nair2020open}{{44}{2020}{{Nair and Menzies}}{{}}}
\bibcite{tanveer2023comprehensive}{{45}{2023{}}{{Tanveer et~al.}}{{Tanveer, Hussain, Zahid, et~al.}}}
\bibcite{yu2021transfer}{{46}{2021}{{Yu et~al.}}{{Yu, Xia, Lo, and Hassan}}}
\gdef \@abspage@last{41}
