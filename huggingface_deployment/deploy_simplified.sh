#!/bin/bash

# Script tri·ªÉn khai l√™n Hugging Face Spaces ƒë∆°n gi·∫£n h√≥a
# Th·ª±c hi·ªán t·ª´ th∆∞ m·ª•c huggingface_deployment
set -e

# C√°c bi·∫øn c·∫•u h√¨nh
HUGGINGFACE_USERNAME="nhathuyvne"  # ƒêi·ªÅn username Hugging Face c·ªßa b·∫°n
SPACE_NAME="requirement-analyzer-api"  # T√™n kh√¥ng gian tr√™n Hugging Face
SPACE_TYPE="docker"  # Lo·∫°i kh√¥ng gian (docker)

echo "=== Chu·∫©n b·ªã tri·ªÉn khai l√™n Hugging Face ==="
echo "Ng∆∞·ªùi d√πng: $HUGGINGFACE_USERNAME"
echo "T√™n kh√¥ng gian: $SPACE_NAME"
echo "Lo·∫°i kh√¥ng gian: $SPACE_TYPE"

# Ki·ªÉm tra ƒë√£ ƒëƒÉng nh·∫≠p ch∆∞a
echo "Ki·ªÉm tra tr·∫°ng th√°i ƒëƒÉng nh·∫≠p Hugging Face..."
if ! huggingface-cli whoami &> /dev/null; then
  echo "ERROR: B·∫°n ch∆∞a ƒëƒÉng nh·∫≠p v√†o Hugging Face CLI. H√£y ch·∫°y 'huggingface-cli login' tr∆∞·ªõc."
  exit 1
fi

# Ki·ªÉm tra n·∫øu kh√¥ng gian ƒë√£ t·ªìn t·∫°i
echo "Ki·ªÉm tra kh√¥ng gian $HUGGINGFACE_USERNAME/$SPACE_NAME..."
huggingface-cli space info $HUGGINGFACE_USERNAME/$SPACE_NAME &> /dev/null
SPACE_EXISTS=$?

# T·∫°o file __init__.py ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ th·ªÉ import ƒë∆∞·ª£c
touch "$DEPLOYMENT_DIR/app/__init__.py"

if [ $SPACE_EXISTS -eq 0 ]; then
  echo "Kh√¥ng gian ƒë√£ t·ªìn t·∫°i, s·∫Ω c·∫≠p nh·∫≠t..."
  huggingface-cli space upload . $HUGGINGFACE_USERNAME/$SPACE_NAME --path-in-space="/" --repo-type="space"
else
  echo "T·∫°o kh√¥ng gian m·ªõi: $HUGGINGFACE_USERNAME/$SPACE_NAME"
  huggingface-cli space create $HUGGINGFACE_USERNAME/$SPACE_NAME --type=$SPACE_TYPE --sdk=docker
  sleep 5  # ƒê·ª£i kh√¥ng gian ƒë∆∞·ª£c t·∫°o
  echo "T·∫£i l√™n t·ªáp tin..."
  huggingface-cli space upload . $HUGGINGFACE_USERNAME/$SPACE_NAME --path-in-space="/" --repo-type="space"
fi

echo "=== Tri·ªÉn khai ho√†n t·∫•t ==="
echo "API c·ªßa b·∫°n s·∫Ω c√≥ s·∫µn t·∫°i: https://$HUGGINGFACE_USERNAME-$SPACE_NAME.hf.space"
echo "T√†i li·ªáu API c√≥ s·∫µn t·∫°i: https://$HUGGINGFACE_USERNAME-$SPACE_NAME.hf.space/docs"
echo ""
echo "L∆∞u √Ω: C√≥ th·ªÉ m·∫•t v√†i ph√∫t ƒë·ªÉ Docker container ƒë∆∞·ª£c x√¢y d·ª±ng v√† kh·ªüi ƒë·ªông tr√™n Hugging Face."

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# T·∫£i c√°c th√†nh ph·∫ßn ph√¢n t√≠ch v√† ∆∞·ªõc l∆∞·ª£ng
from app.requirement_analyzer.analyzer import RequirementAnalyzer
from app.requirement_analyzer.estimator import EffortEstimator
from app.requirement_analyzer.utils import preprocess_text_for_estimation, improve_confidence_level

# Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn
analyzer = RequirementAnalyzer()
estimator = EffortEstimator()

# Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn static v√† templates
templates_dir = os.path.join(os.path.dirname(__file__), "templates")
static_dir = os.path.join(os.path.dirname(__file__), "static")

# Mount static files
if os.path.exists(static_dir):
    app.mount("/static", StaticFiles(directory=static_dir), name="static")

# Thi·∫øt l·∫≠p Jinja2 templates
if os.path.exists(templates_dir):
    templates = Jinja2Templates(directory=templates_dir)
    
    @app.get("/", response_class=HTMLResponse)
    def main_page(request: Request):
        return templates.TemplateResponse("index.html", {"request": request})
else:
    @app.get("/", response_class=HTMLResponse)
    def main_page():
        return """
        <html>
            <head><title>Software Effort Estimation API</title></head>
            <body>
                <h1>Software Effort Estimation API</h1>
                <p>API endpoints available at:</p>
                <ul>
                    <li>/api/estimate - POST endpoint for text-based estimation</li>
                    <li>/api/upload-requirements - POST endpoint for document upload and estimation</li>
                    <li>/docs - API Documentation</li>
                </ul>
            </body>
        </html>
        """

@app.post("/api/estimate")
def estimate_effort(req: RequirementText):
    """
    ∆Ø·ªõc l∆∞·ª£ng n·ªó l·ª±c t·ª´ t√†i li·ªáu y√™u c·∫ßu
    """
    try:
        # Ti·ªÅn x·ª≠ l√Ω v√† l√†m s·∫°ch vƒÉn b·∫£n
        text = preprocess_text_for_estimation(req.text)
        
        # Ph√¢n t√≠ch v√† ∆∞·ªõc l∆∞·ª£ng
        result = estimator.estimate_from_requirements(text, req.method)
        
        # C·∫£i thi·ªán ƒë·ªô tin c·∫≠y
        result = improve_confidence_level(result, text)
        
        return JSONResponse(content=result)
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/upload-requirements")
async def upload_requirements(file: UploadFile = File(...), method: str = Form("weighted_average")):
    """
    T·∫£i l√™n t√†i li·ªáu y√™u c·∫ßu v√† ∆∞·ªõc l∆∞·ª£ng n·ªó l·ª±c
    """
    try:
        # Import parser
        from app.requirement_analyzer.document_parser import DocumentParser
        
        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
        filename = file.filename
        allowed_extensions = ['.txt', '.doc', '.docx', '.pdf', '.md']
        
        file_ext = os.path.splitext(filename)[1].lower()
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"Unsupported file format. Please upload one of: {', '.join(allowed_extensions)}"
            )
            
        # ƒê·ªçc file
        content = await file.read()
        
        # Parse the document
        try:
            parser = DocumentParser()
            text = parser.parse(content, filename)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Error parsing document: {str(e)}")
        
        # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
        text = preprocess_text_for_estimation(text)
        
        # Ph√¢n t√≠ch v√† ∆∞·ªõc l∆∞·ª£ng
        result = estimator.estimate_from_requirements(text, method)
        
        # C·∫£i thi·ªán ƒë·ªô tin c·∫≠y
        result = improve_confidence_level(result, text)
        
        # Th√™m th√¥ng tin v·ªÅ document
        result["document"] = {
            "filename": filename,
            "file_type": file_ext,
            "size_bytes": len(content),
            "text_length": len(text)
        }
        
        return JSONResponse(content=result)
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
def health_check():
    """
    Ki·ªÉm tra tr·∫°ng th√°i ho·∫°t ƒë·ªông c·ªßa API
    """
    return {"status": "ok", "version": "1.0.0"}

# T·∫£i c√°c g√≥i NLTK c·∫ßn thi·∫øt
@app.on_event("startup")
def download_nltk_data():
    try:
        import nltk
        nltk.download('punkt')
        nltk.download('stopwords')
        nltk.download('wordnet')
        nltk.download('averaged_perceptron_tagger')
        try:
            nltk.download('punkt_tab')
        except:
            pass
    except Exception as e:
        print(f"Error downloading NLTK data: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 7860))
    uvicorn.run(app, host="0.0.0.0", port=port)
EOL

# T·∫°o file requirements.txt ƒë∆°n gi·∫£n h∆°n
cat > "$DEPLOYMENT_DIR/requirements.txt" << EOL
fastapi==0.103.1
uvicorn==0.23.2
pydantic==2.3.0
python-multipart==0.0.6
nltk==3.8.1
scikit-learn==1.3.0
numpy==1.25.2
pandas==2.1.0
matplotlib==3.7.3
python-docx==1.0.1
pypdf2==3.0.1
jinja2==3.1.2
EOL

# T·∫°o file README.md cho Hugging Face
cat > "$DEPLOYMENT_DIR/README.md" << EOL
---
title: Software Requirement Analyzer API
emoji: üìä
colorFrom: blue
colorTo: green
sdk: python
app_port: 7860
---

# Software Requirement Analyzer API

This API provides endpoints for analyzing software requirements and estimating development effort based on requirement specifications.

## API Endpoints

### POST /api/estimate
Estimate development effort based on requirement text.

### POST /api/upload-requirements
Upload a requirements document file for analysis.

### GET /health
Check API status
EOL

# T·∫°o file .gitattributes ƒë·ªÉ Hugging Face x·ª≠ l√Ω ƒë√∫ng
cat > "$DEPLOYMENT_DIR/.gitattributes" << EOL
*.7z filter=lfs diff=lfs merge=lfs -text
*.arrow filter=lfs diff=lfs merge=lfs -text
*.bin filter=lfs diff=lfs merge=lfs -text
*.bz2 filter=lfs diff=lfs merge=lfs -text
*.ftz filter=lfs diff=lfs merge=lfs -text
*.gz filter=lfs diff=lfs merge=lfs -text
*.h5 filter=lfs diff=lfs merge=lfs -text
*.joblib filter=lfs diff=lfs merge=lfs -text
*.lfs.* filter=lfs diff=lfs merge=lfs -text
*.mlmodel filter=lfs diff=lfs merge=lfs -text
*.model filter=lfs diff=lfs merge=lfs -text
*.msgpack filter=lfs diff=lfs merge=lfs -text
*.npy filter=lfs diff=lfs merge=lfs -text
*.npz filter=lfs diff=lfs merge=lfs -text
*.onnx filter=lfs diff=lfs merge=lfs -text
*.ot filter=lfs diff=lfs merge=lfs -text
*.parquet filter=lfs diff=lfs merge=lfs -text
*.pb filter=lfs diff=lfs merge=lfs -text
*.pickle filter=lfs diff=lfs merge=lfs -text
*.pkl filter=lfs diff=lfs merge=lfs -text
*.pt filter=lfs diff=lfs merge=lfs -text
*.pth filter=lfs diff=lfs merge=lfs -text
*.rar filter=lfs diff=lfs merge=lfs -text
*.safetensors filter=lfs diff=lfs merge=lfs -text
saved_model/**/* filter=lfs diff=lfs merge=lfs -text
*.tar.* filter=lfs diff=lfs merge=lfs -text
*.tflite filter=lfs diff=lfs merge=lfs -text
*.tgz filter=lfs diff=lfs merge=lfs -text
*.wasm filter=lfs diff=lfs merge=lfs -text
*.xz filter=lfs diff=lfs merge=lfs -text
*.zip filter=lfs diff=lfs merge=lfs -text
*tfevents* filter=lfs diff=lfs merge=lfs -text
EOL

# T·∫°o script download_dependencies.py
cat > "$DEPLOYMENT_DIR/packages.py" << EOL
"""
Utility script for downloading NLTK data
"""
import nltk
import os

def download_packages():
    """
    Downloads required NLTK packages
    """
    # Set NLTK data path
    nltk_data_dir = os.path.expanduser("~/nltk_data")
    os.makedirs(nltk_data_dir, exist_ok=True)
    nltk.data.path.append(nltk_data_dir)
    
    # Download NLTK data
    packages = ['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger']
    for package in packages:
        try:
            nltk.download(package, quiet=True)
            print(f"Downloaded {package}")
        except Exception as e:
            print(f"Error downloading {package}: {e}")
    
    # Special case for punkt_tab
    try:
        nltk.download('punkt_tab', quiet=True)
        print("Downloaded punkt_tab")
    except Exception as e:
        print(f"Error downloading punkt_tab: {e}")
    
if __name__ == "__main__":
    download_packages()
EOL

echo "=== C·∫•u tr√∫c tri·ªÉn khai ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng ==="
echo "Th∆∞ m·ª•c tri·ªÉn khai: $DEPLOYMENT_DIR"
echo "ƒê·ªÉ tri·ªÉn khai l√™n Hugging Face Spaces:"
echo "1. T·∫°o m·ªôt Space m·ªõi tr√™n Hugging Face v·ªõi lo·∫°i 'Gradio/Spaces SDK'"
echo "2. ƒê·∫©y n·ªôi dung th∆∞ m·ª•c $DEPLOYMENT_DIR l√™n repository GitHub c·ªßa Space"
echo "3. Hugging Face s·∫Ω t·ª± ƒë·ªông tri·ªÉn khai ·ª©ng d·ª•ng c·ªßa b·∫°n"